{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型\n",
    "jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细\n",
    "待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8\n",
    "jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用\n",
    "jieba.lcut 以及 jieba.lcut_for_search 直接返回 list\n",
    "\n",
    "jieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\RYAN\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.186 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n",
      "Test Case: 日/ 文章/ 魚怎樣/ 說\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "# should be 日文/ 章魚/ 怎樣/ 說\n",
    "seg_list = jieba.cut(\"日文章魚怎樣說\", cut_all=False)\n",
    "print(\"Test Case: \" + \"/ \".join(seg_list))  # 精确模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入词典\n",
    "\n",
    "开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率\n",
    "用法： jieba.load_userdict(file_name) # file_name 为文件类对象或自定义词典的路径\n",
    "词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。\n",
    "词频省略时使用自动计算的能保证分出该词的词频。\n",
    "\n",
    "例如：\n",
    "\n",
    "创新办 3 i\n",
    "云计算 5\n",
    "凱特琳 nz\n",
    "台中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/\n",
      "/「/台/中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨/烯/」/；/此時/又/可以/分出/來凱/特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    ")\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from R:\\Pythonwork\\jieba\\data\\dict.txt.big ...\n",
      "Dumping model to file cache C:\\Users\\RYAN\\AppData\\Local\\Temp\\jieba.uaefa0d7431ed8e793d8de73261f9773d.cache\n",
      "Loading model cost 3.750 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/\n",
      "/「/台/中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨/烯/」/；/此時/又/可以/分/出來/凱特/琳/了/。\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.set_dictionary('data/dict.txt.big')\n",
    "\n",
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    ")\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新办/主任/也/是/云计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/\n",
      "/「/台中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨/烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict(\"data/userdict.txt\")\n",
    "\n",
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    ")\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case: 日文/ 章魚/ 怎樣/ 說\n"
     ]
    }
   ],
   "source": [
    "# should be 日文/ 章魚/ 怎樣/ 說\n",
    "seg_list = jieba.cut(\"日文章魚怎樣說\", cut_all=False)\n",
    "print(\"Test Case: \" + \"/ \".join(seg_list))  # 精确模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jieba.add_word('日文')\n",
    "jieba.add_word('章魚')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case: 日文/ 章魚/ 怎樣/ 說\n"
     ]
    }
   ],
   "source": [
    "# should be 日文/ 章魚/ 怎樣/ 說\n",
    "seg_list = jieba.cut(\"日文章魚怎樣說\", cut_all=False)\n",
    "print(\"Test Case: \" + \"/ \".join(seg_list))  # 精确模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调整词典\n",
    "\n",
    "使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。\n",
    "\n",
    "使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。\n",
    "\n",
    "注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy/_/install/ /is/ /great\n",
      "python/ /的/正则表达式/是/好/用/的\n",
      "========================================\n",
      "今天天气/不错\n",
      "今天天气 Before: 3, After: 0\n",
      "今天/天气/不错\n",
      "----------------------------------------\n",
      "如果/放到/post/中将/出错/。\n",
      "中将 Before: 763, After: 494\n",
      "如果/放到/post/中/将/出错/。\n",
      "----------------------------------------\n",
      "我们/中/出/了/一个/叛徒\n",
      "中出 Before: 3, After: 3\n",
      "我们/中/出/了/一个/叛徒\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "terms = jieba.cut('easy_install is great')\n",
    "print('/'.join(terms))\n",
    "terms = jieba.cut('python 的正则表达式是好用的')\n",
    "print('/'.join(terms))\n",
    "\n",
    "print(\"=\"*40)\n",
    "# test frequency tune\n",
    "testlist = [\n",
    "('今天天气不错', ('今天', '天气')),\n",
    "('如果放到post中将出错。', ('中', '将')),\n",
    "('我们中出了一个叛徒', ('中', '出')),\n",
    "]\n",
    "\n",
    "for sent, seg in testlist:\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    word = ''.join(seg)\n",
    "    print('%s Before: %s, After: %s' % (word, jieba.get_FREQ(word), jieba.suggest_freq(seg, True)))\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "基于 TF-IDF 算法的关键词抽取\n",
    "import jieba.analyse\n",
    "\n",
    "jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n",
    "\n",
    "- sentence 为待提取的文本\n",
    "\n",
    "- topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\n",
    "\n",
    "- withWeight 为是否一并返回关键词权重值，默认值为 False\n",
    "\n",
    "- allowPOS 仅包括指定词性的词，默认值为空，即不筛选\n",
    "    \n",
    "jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Python How to accept arguments in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "3. 关键词提取\n",
      "----------------------------------------\n",
      " TF-IDF\n",
      "----------------------------------------\n",
      "欧亚 0.7300142700289363\n",
      "吉林 0.659038184373617\n",
      "置业 0.4887134522112766\n",
      "万元 0.3392722481859574\n",
      "增资 0.33582401985234045\n",
      "139.13 0.25435675538085106\n",
      "7000 0.25435675538085106\n",
      "2013 0.25435675538085106\n",
      "4.3 0.25435675538085106\n",
      "实现 0.19900979900382978\n",
      "综合体 0.19480309624702127\n",
      "经营范围 0.19389757253595744\n",
      "亿元 0.1914421623587234\n",
      "在建 0.17541884768425534\n",
      "全资 0.17180164988510638\n",
      "注册资本 0.1712441526\n",
      "百货 0.16734460041382979\n",
      "零售 0.1475057117057447\n",
      "子公司 0.14596045237787234\n",
      "营业 0.13920178509021275\n",
      "----------------------------------------\n",
      " TextRank\n",
      "----------------------------------------\n",
      "欧亚 1.0\n",
      "置业 0.6197259048833487\n",
      "实现 0.544810444969908\n",
      "收入 0.4028423177489152\n",
      "增资 0.38553124799422367\n",
      "子公司 0.3640667974276092\n",
      "城市 0.3574217805005816\n",
      "商业 0.3554320791321217\n",
      "在建 0.30925993271739216\n",
      "零售 0.3054061077010396\n",
      "百货 0.3045608185716206\n",
      "全资 0.2985550683765774\n",
      "开发 0.2934491188690259\n",
      "项目 0.2903401502343987\n",
      "综合体 0.2895519226176092\n",
      "业务 0.28837262558678545\n",
      "营业 0.2793137318262662\n",
      "有限公司 0.2785780879074705\n",
      "注册资本 0.2755679064401766\n",
      "经营范围 0.24592442175412696\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "\n",
    "s = \"此外，公司拟对全资子公司吉林欧亚置业有限公司增资4.3亿元，增资后，吉林欧亚置业注册资本由7000万元增加到5亿元。吉林欧亚置业主要经营范围为房地产开发及百货零售等业务。目前在建吉林欧亚城市商业综合体项目。2013年，实现营业收入0万元，实现净利润-139.13万元。\"\n",
    "\n",
    "print('='*40)\n",
    "print('3. 关键词提取')\n",
    "print('-'*40)\n",
    "print(' TF-IDF')\n",
    "print('-'*40)\n",
    "\n",
    "for x, w in jieba.analyse.extract_tags(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))\n",
    "\n",
    "print('-'*40)\n",
    "print(' TextRank')\n",
    "print('-'*40)\n",
    "\n",
    "for x, w in jieba.analyse.textrank(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "3. 关键词提取\n",
      "----------------------------------------\n",
      " TF-IDF\n",
      "allowPOS=('ns', 'n', 'vn', 'v')\n",
      "----------------------------------------\n",
      "收入 1.0\n",
      "实现 0.9948607905791448\n",
      "增资 0.8811995209165904\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "\n",
    "s = \"此外，公司拟对全资子公司吉林欧亚置业有限公司增资4.3亿元，增资后，吉林欧亚置业注册资本由7000万元增加到5亿元。吉林欧亚置业主要经营范围为房地产开发及百货零售等业务。目前在建吉林欧亚城市商业综合体项目。2013年，实现营业收入0万元，实现净利润-139.13万元。\"\n",
    "\n",
    "print('='*40)\n",
    "print('3. 关键词提取')\n",
    "print('-'*40)\n",
    "print(' TF-IDF')\n",
    "print(\"allowPOS=('ns', 'n', 'vn', 'v')\")\n",
    "print('-'*40)\n",
    "\n",
    "for x, w in jieba.analyse.textrank(s, topK=20, withWeight=True, allowPOS=('v')):\n",
    "    print('%s %s' % (x, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage:    python extract_tags.py [file name] -k [top k]\n",
      "\n",
      "ipykernel_launcher.py: error: no such option: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\jieba\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from optparse import OptionParser\n",
    "\n",
    "USAGE = \"usage:    python extract_tags.py [file name] -k [top k]\"\n",
    "\n",
    "parser = OptionParser(USAGE)\n",
    "parser.add_option(\"-k\", dest=\"topK\")\n",
    "opt, args = parser.parse_args()\n",
    "\n",
    "\n",
    "if len(args) < 1:\n",
    "    print(USAGE)\n",
    "    sys.exit(1)\n",
    "\n",
    "file_name = args[0]\n",
    "\n",
    "if opt.topK is None:\n",
    "    topK = 10\n",
    "else:\n",
    "    topK = int(opt.topK)\n",
    "\n",
    "content = open(file_name, 'rb').read()\n",
    "\n",
    "tags = jieba.analyse.extract_tags(content, topK=topK)\n",
    "\n",
    "print(\",\".join(tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
